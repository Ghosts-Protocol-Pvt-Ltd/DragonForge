#!/bin/bash
# ============================================================================
# DragonForge — Libvirt QEMU Hook for GPU Passthrough
# ============================================================================
# Safely detaches a discrete GPU from the host and binds it to vfio-pci
# for VM passthrough, then returns it to the host on VM shutdown.
#
# This hook uses device-level unbind + driver_override instead of
# kernel module unloading. This means it works even when other processes
# (like a desktop compositor or VS Code) are using the nvidia driver —
# the specific PCI device gets detached, not the entire driver stack.
#
# SAFETY:
#   - No `set -e` — individual command failures are handled gracefully
#   - Built-in timeout watchdog prevents hook from locking libvirtd
#   - GPU temperature check before passthrough (thermal protection)
#   - All operations logged to /var/log/dragonforge.log
#
# Install: sudo cp hooks/qemu /etc/libvirt/hooks/qemu
#          sudo chmod +x /etc/libvirt/hooks/qemu
# ============================================================================

# NOTE: Do NOT use `set -e` here. If a best-effort command (like modprobe -r)
# fails, we must continue to the next step, not abort the entire hook.
set -uo pipefail

GUEST_NAME="${1:-}"
HOOK_NAME="${2:-}"
STATE_NAME="${3:-}"

# ── Configuration ───────────────────────────────────────────────────────────

VM_NAME="${DRAGONFORGE_VM_NAME:-win11-dragonforge}"
GPU_PCI="${DRAGONFORGE_GPU_PCI:-0000:01:00.0}"
GPU_AUDIO="${DRAGONFORGE_GPU_AUDIO:-0000:01:00.1}"
GPU_DRIVER="${DRAGONFORGE_GPU_DRIVER:-nvidia}"
DEVICES="$GPU_PCI $GPU_AUDIO"

# Timeout in seconds — if the hook takes longer than this, it self-terminates
# to prevent libvirtd from hanging forever.
HOOK_TIMEOUT="${DRAGONFORGE_HOOK_TIMEOUT:-60}"

# GPU temperature threshold (°C) — refuse passthrough if GPU is too hot
GPU_TEMP_MAX="${DRAGONFORGE_GPU_TEMP_MAX:-85}"

# Log file
LOG_FILE="/var/log/dragonforge.log"

# ── Logging ─────────────────────────────────────────────────────────────────

LOG_TAG="DragonForge"

log() {
    local msg="$LOG_TAG: $1"
    echo "$msg"
    logger -t "$LOG_TAG" "$1" 2>/dev/null || true
    echo "$(date '+%Y-%m-%d %H:%M:%S') $msg" >> "$LOG_FILE" 2>/dev/null || true
}

warn() {
    local msg="$LOG_TAG: WARNING: $1"
    echo "$msg" >&2
    logger -t "$LOG_TAG" "WARNING: $1" 2>/dev/null || true
    echo "$(date '+%Y-%m-%d %H:%M:%S') $msg" >> "$LOG_FILE" 2>/dev/null || true
}

die() {
    local msg="$LOG_TAG: FATAL: $1"
    echo "$msg" >&2
    logger -t "$LOG_TAG" "FATAL: $1" 2>/dev/null || true
    echo "$(date '+%Y-%m-%d %H:%M:%S') $msg" >> "$LOG_FILE" 2>/dev/null || true
    exit 1
}

# ── Guard ───────────────────────────────────────────────────────────────────

if [ -z "$GUEST_NAME" ] || [ "$GUEST_NAME" != "$VM_NAME" ]; then
    exit 0
fi

# ── Timeout Watchdog ────────────────────────────────────────────────────────
# Prevents the hook from hanging indefinitely (which locks libvirtd).
# If the hook doesn't finish within HOOK_TIMEOUT seconds, it kills itself.

_watchdog_cleanup() {
    # Kill the watchdog background process on normal exit
    if [ -n "${WATCHDOG_PID:-}" ]; then
        kill "$WATCHDOG_PID" 2>/dev/null || true
        wait "$WATCHDOG_PID" 2>/dev/null || true
    fi
}
trap _watchdog_cleanup EXIT

(
    sleep "$HOOK_TIMEOUT"
    warn "Hook timeout after ${HOOK_TIMEOUT}s — self-terminating to prevent libvirtd hang"
    kill -TERM $$ 2>/dev/null || true
    sleep 2
    kill -KILL $$ 2>/dev/null || true
) </dev/null &>/dev/null &
WATCHDOG_PID=$!

# ── Helpers ─────────────────────────────────────────────────────────────────

unbind_device() {
    local dev="$1"
    if [ -e "/sys/bus/pci/devices/$dev/driver" ]; then
        local current_driver
        current_driver=$(basename "$(readlink "/sys/bus/pci/devices/$dev/driver" 2>/dev/null)" 2>/dev/null)
        log "Unbinding $dev from ${current_driver:-unknown}"
        echo "$dev" > "/sys/bus/pci/devices/$dev/driver/unbind" 2>/dev/null || {
            warn "Failed to unbind $dev"
            return 1
        }
        # Wait for unbind to complete (max 5s)
        local i=0
        while [ -e "/sys/bus/pci/devices/$dev/driver" ] && [ "$i" -lt 10 ]; do
            sleep 0.5
            i=$((i + 1))
        done
        if [ -e "/sys/bus/pci/devices/$dev/driver" ]; then
            warn "$dev still bound after 5s wait"
            return 1
        fi
    else
        log "$dev has no driver bound — OK"
    fi
    return 0
}

bind_vfio() {
    local dev="$1"
    log "Binding $dev to vfio-pci"
    if ! echo "vfio-pci" > "/sys/bus/pci/devices/$dev/driver_override" 2>/dev/null; then
        warn "Failed to set driver_override for $dev"
        return 1
    fi
    echo "$dev" > /sys/bus/pci/drivers/vfio-pci/bind 2>/dev/null || true
    return 0
}

verify_vfio() {
    local dev="$1"
    local driver
    driver=$(basename "$(readlink "/sys/bus/pci/devices/$dev/driver" 2>/dev/null)" 2>/dev/null)
    if [ "$driver" = "vfio-pci" ]; then
        log "$dev OK — bound to vfio-pci"
        return 0
    else
        warn "$dev is on '${driver:-none}', expected vfio-pci"
        return 1
    fi
}

check_gpu_temperature() {
    # Check GPU temperature via nvidia-smi (if available)
    if ! command -v nvidia-smi &>/dev/null; then
        log "nvidia-smi not available — skipping temperature check"
        return 0
    fi
    local temp
    temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits 2>/dev/null | head -1)
    if [ -n "$temp" ] && [ "$temp" -gt 0 ] 2>/dev/null; then
        log "GPU temperature: ${temp}°C (max: ${GPU_TEMP_MAX}°C)"
        if [ "$temp" -ge "$GPU_TEMP_MAX" ]; then
            die "GPU temperature ${temp}°C exceeds safe limit ${GPU_TEMP_MAX}°C — aborting passthrough to protect hardware"
        fi
    fi
    return 0
}

# ── Prepare: Detach GPU for VM ──────────────────────────────────────────────

if [ "$HOOK_NAME" = "prepare" ] && [ "$STATE_NAME" = "begin" ]; then
    log "=== Preparing GPU passthrough for $VM_NAME ==="

    # Clean up stale QEMU domain directories (prevents SELinux master-key.aes conflicts)
    for stale_dir in /var/lib/libvirt/qemu/domain-*-"${VM_NAME}"; do
        if [ -d "$stale_dir" ]; then
            log "Cleaning stale QEMU state: $stale_dir"
            rm -rf "$stale_dir" 2>/dev/null || true
        fi
    done

    # Hardware health check
    check_gpu_temperature

    # ── Laptop dGPU: Release VT consoles & framebuffer ──────────────────────
    # On hybrid laptops, DRM subsystem may hold references to the dGPU even
    # when the compositor runs on the iGPU. Releasing VT console bindings and
    # the EFI framebuffer allows nvidia_drm to be cleanly unloaded.
    log "Releasing VT consoles and framebuffer"
    for vtcon in /sys/class/vtconsole/vtcon*/bind; do
        echo 0 > "$vtcon" 2>/dev/null || true
    done
    if [ -e /sys/bus/platform/drivers/efi-framebuffer/efi-framebuffer.0 ]; then
        echo efi-framebuffer.0 > /sys/bus/platform/drivers/efi-framebuffer/unbind 2>/dev/null || true
        log "Unbound EFI framebuffer"
    fi

    # ── Kill any processes holding nvidia device references ──────────────────
    # On some setups, stale nvidia-persistenced or nvidia-smi can hold refs
    if command -v nvidia-smi &>/dev/null; then
        gpu_pids=$(nvidia-smi --query-compute-apps=pid --format=csv,noheader,nounits 2>/dev/null || true)
        if [ -n "$gpu_pids" ]; then
            log "Killing GPU processes: $gpu_pids"
            for pid in $gpu_pids; do
                kill -9 "$pid" 2>/dev/null || true
            done
            sleep 1
        fi
    fi
    # Stop nvidia-persistenced if running
    if systemctl is-active nvidia-persistenced &>/dev/null; then
        systemctl stop nvidia-persistenced 2>/dev/null || true
        log "Stopped nvidia-persistenced"
    fi

    # ── Unload GPU driver modules (strict order) ────────────────────────────
    gpu_modules=()
    case "$GPU_DRIVER" in
        nvidia)   gpu_modules=(nvidia_drm nvidia_modeset nvidia_uvm nvidia) ;;
        nouveau)  gpu_modules=(nouveau) ;;
        amdgpu)   gpu_modules=(amdgpu) ;;
        radeon)   gpu_modules=(radeon) ;;
        *)        gpu_modules=(nvidia_drm nvidia_modeset nvidia_uvm nvidia nouveau amdgpu radeon) ;;
    esac

    modules_unloaded=true
    for mod in "${gpu_modules[@]}"; do
        if lsmod | grep -q "^${mod}"; then
            # Retry up to 3 times with short waits
            attempt=0
            while [ "$attempt" -lt 3 ]; do
                if modprobe -r "$mod" 2>/dev/null; then
                    log "Unloaded $mod"
                    break
                fi
                attempt=$((attempt + 1))
                sleep 1
            done
            if lsmod | grep -q "^${mod}"; then
                warn "$mod still loaded after 3 attempts (refcount: $(cat /sys/module/$mod/refcount 2>/dev/null || echo '?'))"
                modules_unloaded=false
            fi
        fi
    done

    if [ "$modules_unloaded" = false ]; then
        warn "Some modules could not be unloaded — attempting device-level unbind anyway"
    fi

    # ── Unbind each device from its current driver ──────────────────────────
    for dev in $DEVICES; do
        unbind_device "$dev" || true
    done

    # Small settle delay for kernel to process unbinds
    sleep 0.5

    # ── Bind each device to vfio-pci ────────────────────────────────────────
    for dev in $DEVICES; do
        bind_vfio "$dev" || true
    done

    # Verify all devices are on vfio-pci
    verify_failed=0
    for dev in $DEVICES; do
        if ! verify_vfio "$dev"; then
            verify_failed=1
        fi
    done

    if [ "$verify_failed" -eq 1 ]; then
        die "One or more devices failed to bind to vfio-pci. Aborting VM start."
    fi

    log "=== GPU ready for passthrough ==="

# ── Release: Return GPU to host ────────────────────────────────────────────

elif [ "$HOOK_NAME" = "release" ] && [ "$STATE_NAME" = "end" ]; then
    log "=== Returning GPU to host (forking to background) ==="

    # CRITICAL: The release hook MUST return quickly or it blocks virtqemud.
    # Fork the entire GPU restoration into the background so libvirt can
    # continue processing. The background process handles everything.
    (
        # Give QEMU a moment to fully release the devices
        sleep 1

        # Clean up stale QEMU domain directory (prevents SELinux label conflicts on next start)
        for stale_dir in /var/lib/libvirt/qemu/domain-*-"${VM_NAME}"; do
            if [ -d "$stale_dir" ]; then
                log "Cleaning stale QEMU domain dir: $stale_dir"
                rm -rf "$stale_dir" 2>/dev/null || true
            fi
        done

        # Unbind from vfio-pci
        for dev in $DEVICES; do
            if [ -e "/sys/bus/pci/devices/$dev/driver" ]; then
                current_driver=$(basename "$(readlink "/sys/bus/pci/devices/$dev/driver" 2>/dev/null)" 2>/dev/null)
                log "Unbinding $dev from ${current_driver:-unknown}"
                echo "$dev" > "/sys/bus/pci/devices/$dev/driver/unbind" 2>/dev/null || true
                # Wait for unbind (max 3s)
                for i in $(seq 1 6); do
                    [ ! -e "/sys/bus/pci/devices/$dev/driver" ] && break
                    sleep 0.5
                done
            fi
        done

        # Clear driver override so the original driver can reclaim
        for dev in $DEVICES; do
            echo "" > "/sys/bus/pci/devices/$dev/driver_override" 2>/dev/null || true
        done

        # Trigger PCI rescan
        log "Rescanning PCI bus"
        echo 1 > /sys/bus/pci/rescan 2>/dev/null || true
        sleep 2

        # Best-effort reload GPU driver stack
        reload_modules=()
        case "$GPU_DRIVER" in
            nvidia)   reload_modules=(nvidia nvidia_modeset nvidia_uvm nvidia_drm) ;;
            nouveau)  reload_modules=(nouveau) ;;
            amdgpu)   reload_modules=(amdgpu) ;;
            radeon)   reload_modules=(radeon) ;;
            *)        reload_modules=(nvidia nvidia_modeset nvidia_uvm nvidia_drm) ;;
        esac

        for mod in "${reload_modules[@]}"; do
            if modprobe "$mod" 2>/dev/null; then
                log "Loaded $mod"
            else
                log "Could not load $mod (may not be needed)"
            fi
        done

        # Explicit rebind: if the device didn't auto-claim, manually bind to GPU driver
        sleep 1
        for dev in $DEVICES; do
            driver=$(basename "$(readlink "/sys/bus/pci/devices/$dev/driver" 2>/dev/null)" 2>/dev/null)
            if [ -z "$driver" ]; then
                log "$dev has no driver — attempting explicit bind"

                # Determine which driver to try based on device type
                dev_class=$(cat "/sys/bus/pci/devices/$dev/class" 2>/dev/null)

                # Audio device (0x040300) → snd_hda_intel; GPU (0x030000) → nvidia
                if [ "${dev_class:0:6}" = "0x0403" ]; then
                    try_drivers=(snd_hda_intel)
                    log "$dev is audio device — trying snd_hda_intel"
                else
                    try_drivers=("$GPU_DRIVER")
                    case "$GPU_DRIVER" in
                        nvidia)   try_drivers+=(nouveau) ;;
                        nouveau)  try_drivers+=(nvidia) ;;
                        amdgpu)   try_drivers+=(radeon) ;;
                        radeon)   try_drivers+=(amdgpu) ;;
                    esac
                fi

                for try_driver in "${try_drivers[@]}"; do
                    if [ -d "/sys/bus/pci/drivers/$try_driver" ]; then
                        echo "$dev" > "/sys/bus/pci/drivers/$try_driver/bind" 2>/dev/null && {
                            log "$dev explicitly bound to $try_driver"
                            break
                        } || true
                    fi
                done
                # Final check
                sleep 0.5
                driver=$(basename "$(readlink "/sys/bus/pci/devices/$dev/driver" 2>/dev/null)" 2>/dev/null)
            fi

            if [ -n "$driver" ]; then
                log "$dev returned to $driver"
            else
                warn "$dev has no driver after release — may need 'dragonforge reset'"
            fi
        done

        # Restore VT consoles
        log "Restoring VT consoles"
        for vtcon in /sys/class/vtconsole/vtcon*/bind; do
            echo 1 > "$vtcon" 2>/dev/null || true
        done

        # Restart nvidia-persistenced if it was running before
        if systemctl is-enabled nvidia-persistenced &>/dev/null; then
            systemctl start nvidia-persistenced 2>/dev/null || true
            log "Restarted nvidia-persistenced"
        fi

        log "=== GPU returned to host ==="
    ) </dev/null &>/dev/null &
    disown
    log "Release hook returned (GPU restoration running in background)"
fi
